{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'RND/train'\n",
    "valid_path = 'RND/valid'\n",
    "dirs = list(map(str, range(1, 10 + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=8,\n",
    "                                   width_shift_range=0.08,\n",
    "                                   shear_range=0.3,\n",
    "                                   height_shift_range=0.08,\n",
    "                                   zoom_range=0.08).flow_from_directory(train_path, target_size=(28, 28),\n",
    "                                                        classes=dirs, batch_size=10, color_mode='grayscale')\n",
    "valid_batches = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=8,\n",
    "                                   width_shift_range=0.08,\n",
    "                                   shear_range=0.3,\n",
    "                                   height_shift_range=0.08,\n",
    "                                   zoom_range=0.08).flow_from_directory(valid_path, target_size=(28, 28),\n",
    "                                                        classes=dirs, batch_size=10, color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = keras.applications.vgg16.VGG16()\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, (3, 3), input_shape=(1, 28, 28), activation='relu'))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model1():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(1, 28, 28)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 7s - loss: 0.2276 - acc: 0.9300 - val_loss: 0.3083 - val_acc: 0.9000\n",
      "Epoch 2/30\n",
      " - 7s - loss: 0.1736 - acc: 0.9625 - val_loss: 0.4936 - val_acc: 0.8300\n",
      "Epoch 3/30\n",
      " - 7s - loss: 0.1846 - acc: 0.9525 - val_loss: 0.2705 - val_acc: 0.9200\n",
      "Epoch 4/30\n",
      " - 7s - loss: 0.1933 - acc: 0.9425 - val_loss: 0.3145 - val_acc: 0.9200\n",
      "Epoch 5/30\n",
      " - 7s - loss: 0.2989 - acc: 0.9050 - val_loss: 0.4779 - val_acc: 0.8400\n",
      "Epoch 6/30\n",
      " - 8s - loss: 0.2220 - acc: 0.9475 - val_loss: 0.3718 - val_acc: 0.8900\n",
      "Epoch 7/30\n",
      " - 7s - loss: 0.2185 - acc: 0.9350 - val_loss: 0.4804 - val_acc: 0.9100\n",
      "Epoch 8/30\n",
      " - 7s - loss: 0.2046 - acc: 0.9300 - val_loss: 0.5225 - val_acc: 0.8600\n",
      "Epoch 9/30\n",
      " - 7s - loss: 0.2073 - acc: 0.9375 - val_loss: 0.3074 - val_acc: 0.9100\n",
      "Epoch 10/30\n",
      " - 7s - loss: 0.1859 - acc: 0.9450 - val_loss: 0.2866 - val_acc: 0.9200\n",
      "Epoch 11/30\n",
      " - 7s - loss: 0.2030 - acc: 0.9575 - val_loss: 0.4350 - val_acc: 0.8600\n",
      "Epoch 12/30\n",
      " - 7s - loss: 0.1614 - acc: 0.9525 - val_loss: 0.2916 - val_acc: 0.8900\n",
      "Epoch 13/30\n",
      " - 7s - loss: 0.1782 - acc: 0.9400 - val_loss: 0.2832 - val_acc: 0.9100\n",
      "Epoch 14/30\n",
      " - 7s - loss: 0.1432 - acc: 0.9575 - val_loss: 0.3021 - val_acc: 0.9100\n",
      "Epoch 15/30\n",
      " - 7s - loss: 0.1587 - acc: 0.9575 - val_loss: 0.3259 - val_acc: 0.9000\n",
      "Epoch 16/30\n",
      " - 7s - loss: 0.1781 - acc: 0.9400 - val_loss: 0.2996 - val_acc: 0.9000\n",
      "Epoch 17/30\n",
      " - 7s - loss: 0.1264 - acc: 0.9675 - val_loss: 0.2562 - val_acc: 0.9200\n",
      "Epoch 18/30\n",
      " - 7s - loss: 0.1281 - acc: 0.9625 - val_loss: 0.2255 - val_acc: 0.9400\n",
      "Epoch 19/30\n",
      " - 7s - loss: 0.1535 - acc: 0.9475 - val_loss: 0.7431 - val_acc: 0.7500\n",
      "Epoch 20/30\n",
      " - 7s - loss: 0.1386 - acc: 0.9575 - val_loss: 0.2115 - val_acc: 0.9600\n",
      "Epoch 21/30\n",
      " - 7s - loss: 0.1781 - acc: 0.9375 - val_loss: 0.3567 - val_acc: 0.9200\n",
      "Epoch 22/30\n",
      " - 7s - loss: 0.1474 - acc: 0.9600 - val_loss: 0.2416 - val_acc: 0.9300\n",
      "Epoch 23/30\n",
      " - 7s - loss: 0.1778 - acc: 0.9450 - val_loss: 0.2961 - val_acc: 0.9300\n",
      "Epoch 24/30\n",
      " - 7s - loss: 0.1738 - acc: 0.9350 - val_loss: 0.3354 - val_acc: 0.9000\n",
      "Epoch 25/30\n",
      " - 7s - loss: 0.1678 - acc: 0.9525 - val_loss: 0.3932 - val_acc: 0.8800\n",
      "Epoch 26/30\n",
      " - 7s - loss: 0.1825 - acc: 0.9350 - val_loss: 0.2019 - val_acc: 0.9400\n",
      "Epoch 27/30\n",
      " - 7s - loss: 0.1225 - acc: 0.9650 - val_loss: 0.2851 - val_acc: 0.9300\n",
      "Epoch 28/30\n",
      " - 7s - loss: 0.1567 - acc: 0.9525 - val_loss: 0.2311 - val_acc: 0.9400\n",
      "Epoch 29/30\n",
      " - 7s - loss: 0.1179 - acc: 0.9650 - val_loss: 0.2996 - val_acc: 0.9200\n",
      "Epoch 30/30\n",
      " - 7s - loss: 0.1526 - acc: 0.9475 - val_loss: 0.3434 - val_acc: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fb60860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit_generator(train_batches, steps_per_epoch=40, \n",
    "                    validation_data=valid_batches, validation_steps=10, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=8,\n",
    "                                   width_shift_range=0.08,\n",
    "                                   shear_range=0.3,\n",
    "                                   height_shift_range=0.08,\n",
    "                                   zoom_range=0.08).flow_from_directory('RND/test', target_size=(28, 28),\n",
    "                                                        classes=dirs, batch_size=20, color_mode='grayscale', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batches, steps=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  2,  2,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,  9,\n",
       "       10, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(np.argmax, predictions))) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights/conv1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
